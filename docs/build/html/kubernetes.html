

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Kubernetes &mdash; Kube Docs 0.0.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example 1 - Simple - Agricarta Preprocessing" href="example1-agricartapreprocessing.html" />
    <link rel="prev" title="Docker" href="docker.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> Kube Docs
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="docker.html">Docker</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Kubernetes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#yaml-manifests">YAML Manifests</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pods-and-containers">Pods and Containers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-pod-yaml">Example Pod YAML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pod-definition-key-aspects">Pod Definition Key Aspects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#common-commands-for-pods">Common Commands for Pods</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#services">Services</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-service-yaml">Example Service YAML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#service-definition-key-aspects">Service Definition Key Aspects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#commands-for-services">Commands for Services</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ingress">Ingress</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-ingress-yaml">Example Ingress YAML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ingress-definition-key-aspects">Ingress Definition Key Aspects</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ingress-commands">Ingress Commands</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#deployments">Deployments</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-deployment-yaml">Example Deployment YAML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#deployment-commands">Deployment Commands</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#configmaps">Configmaps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-creating-a-configmap">Example Creating A Configmap</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#secrets">Secrets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#persistent-volumes-and-claims">Persistent Volumes and Claims</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-persistent-volume-and-claim-yaml">Example Persistent Volume and Claim YAML</a></li>
<li class="toctree-l3"><a class="reference internal" href="#nfs">NFS</a></li>
<li class="toctree-l3"><a class="reference internal" href="#auto-provisioning">Auto Provisioning</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#helm-standardized-deployment-format">Helm: Standardized Deployment Format</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#example-of-using-helm">Example of Using Helm</a></li>
<li class="toctree-l3"><a class="reference internal" href="#helm-charts">Helm Charts</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example1-agricartapreprocessing.html">Example 1 - Simple - Agricarta Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="example2-landsatdownloaderservice.html">Example 2 - Simple - Landsat Downloader Service</a></li>
<li class="toctree-l1"><a class="reference internal" href="example3-datacube.html">Example 3 - Complex - Datacube</a></li>
<li class="toctree-l1"><a class="reference internal" href="example4-tileviewerapi.html">Example 4 - Complex - Tile Viewer API</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Kube Docs</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Kubernetes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/kubernetes.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="kubernetes">
<h1><a class="toc-backref" href="#id1">Kubernetes</a><a class="headerlink" href="#kubernetes" title="Permalink to this headline">Â¶</a></h1>
<p>Kubernetes is a container orchestration tool for deploying containers across many different physical machines organized into a cluster. We will cover only the very basics of getting a container you created up and running on Kubernetes. It is assumed that a cluster is already set up and can be accessed with the <code class="code docutils literal notranslate"><span class="pre">kubectl</span></code> utility from your local machine. The official <a class="reference external" href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/">Kubernetes documentation</a> has good tutorials for setting up a cluster using <code class="code docutils literal notranslate"><span class="pre">kubeadm</span></code>, and for local development and learning <a class="reference external" href="https://kubernetes.io/docs/setup/learning-environment/minikube/">Minikube</a> is easy to set up and get going with. It is assumed that the cluster is already set up or a managed Kubernetes service is available to you such as EKS or AKS.</p>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#kubernetes" id="id1">Kubernetes</a></p>
<ul>
<li><p><a class="reference internal" href="#yaml-manifests" id="id2">YAML Manifests</a></p></li>
<li><p><a class="reference internal" href="#pods-and-containers" id="id3">Pods and Containers</a></p>
<ul>
<li><p><a class="reference internal" href="#example-pod-yaml" id="id4">Example Pod YAML</a></p></li>
<li><p><a class="reference internal" href="#pod-definition-key-aspects" id="id5">Pod Definition Key Aspects</a></p></li>
<li><p><a class="reference internal" href="#common-commands-for-pods" id="id6">Common Commands for Pods</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#services" id="id7">Services</a></p>
<ul>
<li><p><a class="reference internal" href="#example-service-yaml" id="id8">Example Service YAML</a></p></li>
<li><p><a class="reference internal" href="#service-definition-key-aspects" id="id9">Service Definition Key Aspects</a></p></li>
<li><p><a class="reference internal" href="#commands-for-services" id="id10">Commands for Services</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#ingress" id="id11">Ingress</a></p>
<ul>
<li><p><a class="reference internal" href="#example-ingress-yaml" id="id12">Example Ingress YAML</a></p></li>
<li><p><a class="reference internal" href="#ingress-definition-key-aspects" id="id13">Ingress Definition Key Aspects</a></p></li>
<li><p><a class="reference internal" href="#ingress-commands" id="id14">Ingress Commands</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#deployments" id="id15">Deployments</a></p>
<ul>
<li><p><a class="reference internal" href="#example-deployment-yaml" id="id16">Example Deployment YAML</a></p></li>
<li><p><a class="reference internal" href="#deployment-commands" id="id17">Deployment Commands</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#configmaps" id="id18">Configmaps</a></p>
<ul>
<li><p><a class="reference internal" href="#example-creating-a-configmap" id="id19">Example Creating A Configmap</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#secrets" id="id20">Secrets</a></p></li>
<li><p><a class="reference internal" href="#persistent-volumes-and-claims" id="id21">Persistent Volumes and Claims</a></p>
<ul>
<li><p><a class="reference internal" href="#example-persistent-volume-and-claim-yaml" id="id22">Example Persistent Volume and Claim YAML</a></p></li>
<li><p><a class="reference internal" href="#nfs" id="id23">NFS</a></p></li>
<li><p><a class="reference internal" href="#auto-provisioning" id="id24">Auto Provisioning</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#helm-standardized-deployment-format" id="id25">Helm: Standardized Deployment Format</a></p>
<ul>
<li><p><a class="reference internal" href="#example-of-using-helm" id="id26">Example of Using Helm</a></p></li>
<li><p><a class="reference internal" href="#helm-charts" id="id27">Helm Charts</a></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="yaml-manifests">
<h2><a class="toc-backref" href="#id2">YAML Manifests</a><a class="headerlink" href="#yaml-manifests" title="Permalink to this headline">Â¶</a></h2>
<p>Resources on Kubernetes are defined by <code class="code docutils literal notranslate"><span class="pre">.yaml</span></code> format manifest files. Manifest files can be applied to the cluster using <code class="code docutils literal notranslate"><span class="pre">kubectl</span></code>, the Kubernetes command line interface, using <code class="code docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">apply</span> <span class="pre">-f</span> <span class="pre">manifest.yaml</span></code>. For each resource type below an example <code class="code docutils literal notranslate"><span class="pre">.yaml</span></code> file will be provided.</p>
</div>
<div class="section" id="pods-and-containers">
<h2><a class="toc-backref" href="#id3">Pods and Containers</a><a class="headerlink" href="#pods-and-containers" title="Permalink to this headline">Â¶</a></h2>
<p>Pods are the smallest building block of Kubernetes that can be queried directly. The can contain one or more containers, and the containers can expose ports in order to be accessed individually from the overall pod. Volumes can be mounted and assigned to individual containers. Pods have labels which allow services to direct traffic to specific containers within a pod. Think of a pod as a grouping of containers. Different pods can communicate with each other in different ways, including a shared message queue such as Rabbit MQ. In this way, related containers do not have to be in the same pod. In fact, it is common for pods to have only a single container.</p>
<div class="section" id="example-pod-yaml">
<h3><a class="toc-backref" href="#id4">Example Pod YAML</a><a class="headerlink" href="#example-pod-yaml" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Pod</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ubuntu-worker</span>
<span class="nt">labels</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ubuntu-worker</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">containers</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ubuntu-worker-container</span>
    <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry.kub-eo.agr.gc.ca/ubuntu-base:v0.0.8</span>
    <span class="nt">ports</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">web</span>
        <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfsvol</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/mnt/zeusdrobo</span>
    <span class="nt">command</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;sleep&quot;</span>
    <span class="nt">args</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="s">&quot;infinity&quot;</span>
<span class="nt">imagePullSecrets</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">regcred</span>
<span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfsvol</span>
    <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
        <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-pvc-miniostorage</span>
</pre></div>
</div>
</div>
<div class="section" id="pod-definition-key-aspects">
<h3><a class="toc-backref" href="#id5">Pod Definition Key Aspects</a><a class="headerlink" href="#pod-definition-key-aspects" title="Permalink to this headline">Â¶</a></h3>
<dl class="simple">
<dt>name</dt><dd><p>Used for querying the status of the pod.</p>
</dd>
<dt>labels</dt><dd><p>Used to identify the pod so that services can correctly send traffic to the right pod. In the service definition <code class="code docutils literal notranslate"><span class="pre">selectors</span></code> are used to match the <code class="code docutils literal notranslate"><span class="pre">labels</span></code> defined for the pod.</p>
</dd>
<dt>containers:image</dt><dd><p>Specifies the image for the container.</p>
</dd>
<dt>containers:ports</dt><dd><p>Specifies the ports exposed by the container, and therefore the pod.</p>
</dd>
<dt>containers:volumeMounts</dt><dd><p>Specifies which of the volumes defined for the pod will be mounted in this container and to which path.</p>
</dd>
<dt>containers:command and args</dt><dd><p>The command the container will run on start up with which variables.</p>
</dd>
<dt>imagePullSecrets</dt><dd><p>The credentials for your private registry so that Kubernetes is able to pull the image. This requires some extra steps to set up which will be covered in the <a class="reference internal" href="#secrets"><span class="std std-ref">secret section</span></a>.</p>
</dd>
<dt>volumes</dt><dd><p>The persistent volume claim that allows the pod to take a share of a persistent volume and provide that persistence to its containers as a mount point.</p>
</dd>
</dl>
</div>
<div class="section" id="common-commands-for-pods">
<h3><a class="toc-backref" href="#id6">Common Commands for Pods</a><a class="headerlink" href="#common-commands-for-pods" title="Permalink to this headline">Â¶</a></h3>
<p>View all pods for the default namespace:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods
</pre></div>
</div>
<p>View pods for a specific namespace:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods --namespace namespace_name
</pre></div>
</div>
<p>View pods for all namespaces:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pods -A
</pre></div>
</div>
<p>View details for a pod:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl describe pod pod_name
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get pod pod_name -o yaml
</pre></div>
</div>
<p>View logs for a pod with one container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl logs pod_name
</pre></div>
</div>
<p>View logs for a pod with many containers:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl logs pod_name -c container_name
</pre></div>
</div>
<p>Interact inside a container:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl <span class="nb">exec</span> -it pod_name -- bash
</pre></div>
</div>
<p>Similarly to logs, if you have a pod with more then one container, use <code class="code docutils literal notranslate"><span class="pre">-c</span></code> to specify the container.</p>
<p>Delete a pod:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl delete pod pod_name
</pre></div>
</div>
<p>When you delete a pod, it doesnât get recreated automatically; that is where a <a class="reference internal" href="#deployments"><span class="std std-ref">deployment</span></a> comes in handy. Often to re-apply a new configuration or if there are problems with a pod, you will need to delete it and re-apply the manifest to recreate the pod.</p>
<p>Pods are where your code runs, and services are how your code communicates inside the cluster and out.</p>
</div>
</div>
<div class="section" id="services">
<h2><a class="toc-backref" href="#id7">Services</a><a class="headerlink" href="#services" title="Permalink to this headline">Â¶</a></h2>
<p>Services provide an interface to communicate with the applications running in your pods. The two major types of services are <code class="code docutils literal notranslate"><span class="pre">ClusterIP</span></code> and <code class="code docutils literal notranslate"><span class="pre">NodePort</span></code>. ClusterIPs are used for inter-cluster communication, while NodePorts enable communication from outside the cluster. For pod to pod communication it is common to use ClusterIP services to do this. NodePorts require access to the IP or hostname of the nodes (the physical hardware providing the resources required by your pods) running your cluster, and the service is differentiated by the port number. A nicer way of allowing access from outside your cluster is with subdomains through an Ingress and ingress manager like a load balancer. That will be covered in the <a class="reference internal" href="#ingress"><span class="std std-ref">ingress section</span></a>.</p>
<p>So if you want to access a pod running a service on port 6379, and one of your nodeâs IP address is 10.117.206.94, you would create a <code class="code docutils literal notranslate"><span class="pre">NodePort</span></code> service that has a nodePort of 30637, and selectors that are equivalent to the podâs labels. The result is that your podâs service is accessible outside the cluster at <code class="code docutils literal notranslate"><span class="pre">10.117.206.94:30637</span></code>. If your node had a hostname assigned to it, you could also use that, so it would be <code class="code docutils literal notranslate"><span class="pre">node_hostname.local:30637</span></code>.</p>
<p>If you donât specify your nodePort, one will be automatically assigned in the range of port numbers between 30000-32000. Keep this range in mind when manually specifying node ports. Ports in this range will not conflict with the default ports in use on your node.</p>
<p>ClusterIP services donât have a nodePort and are not accessible by machines outside the cluster.</p>
<div class="section" id="example-service-yaml">
<h3><a class="toc-backref" href="#id8">Example Service YAML</a><a class="headerlink" href="#example-service-yaml" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Service</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis-service</span>
<span class="nt">labels</span><span class="p">:</span>
    <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis-service</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">type</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">NodePort</span>
<span class="nt">ports</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">port</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6379</span>
    <span class="nt">nodePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">30637</span>
    <span class="nt">targetPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6379</span>
<span class="nt">selector</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis</span>
    <span class="nt">release</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">redis-dev</span>
    <span class="nt">role</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">master</span>
</pre></div>
</div>
</div>
<div class="section" id="service-definition-key-aspects">
<h3><a class="toc-backref" href="#id9">Service Definition Key Aspects</a><a class="headerlink" href="#service-definition-key-aspects" title="Permalink to this headline">Â¶</a></h3>
<dl class="simple">
<dt><code class="code docutils literal notranslate"><span class="pre">type</span></code></dt><dd><p>Can be <code class="code docutils literal notranslate"><span class="pre">NodePort</span></code> or <code class="code docutils literal notranslate"><span class="pre">ClusterIP</span></code>.</p>
</dd>
<dt><code class="code docutils literal notranslate"><span class="pre">ports</span></code></dt><dd><p>Defines the port that the service will send traffic to on the pod (port and targetPort), while for <code class="code docutils literal notranslate"><span class="pre">NodePort</span></code> the nodePort defines what port on your node that requests will be coming from.</p>
</dd>
<dt><code class="code docutils literal notranslate"><span class="pre">selector</span></code></dt><dd><p>Corresponds to the <code class="code docutils literal notranslate"><span class="pre">labels</span></code> defined on the pod you are wanting to send traffic to. For example, if you pod has a label <code class="code docutils literal notranslate"><span class="pre">name:</span> <span class="pre">ubuntu-worker</span></code>, then your selector will have <code class="code docutils literal notranslate"><span class="pre">name:</span> <span class="pre">ubuntu-worker</span></code> as well.</p>
</dd>
</dl>
</div>
<div class="section" id="commands-for-services">
<h3><a class="toc-backref" href="#id10">Commands for Services</a><a class="headerlink" href="#commands-for-services" title="Permalink to this headline">Â¶</a></h3>
<p>See the <a class="reference internal" href="#common-commands-for-pods"><span class="std std-ref">common commands for Pods section</span></a> for examples on how to fetch services using <code class="code docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">get</span></code> and <code class="code docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">describe</span></code> with the resource type <code class="code docutils literal notranslate"><span class="pre">svc</span></code>.</p>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get svc
</pre></div>
</div>
<p>The above will show all the services for the default namespace.</p>
<p>Deleting services works the same as pods as well.</p>
</div>
</div>
<div class="section" id="ingress">
<h2><a class="toc-backref" href="#id11">Ingress</a><a class="headerlink" href="#ingress" title="Permalink to this headline">Â¶</a></h2>
<p>Ingress is a special kind of service that differentiates the destination of the traffic based on the domain the request came from. This requires a load balancer which will be a assigned an IP address that is accessible outside the cluster. This load balancer IP can be assigned an A record (a primary DNS entry that points to machine IPs), such as <code class="code docutils literal notranslate"><span class="pre">ingress.kub-eo.agr.gc.ca</span></code>. Once that <code class="code docutils literal notranslate"><span class="pre">A</span> <span class="pre">record</span></code> is in place, <code class="code docutils literal notranslate"><span class="pre">CNAME</span> <span class="pre">records</span></code> (alias DNS records that point domain names to <code class="code docutils literal notranslate"><span class="pre">A</span> <span class="pre">record`s)</span> <span class="pre">can</span> <span class="pre">be</span> <span class="pre">created</span> <span class="pre">that</span> <span class="pre">point</span> <span class="pre">to</span> <span class="pre">`ingress.kub-eo.agr.gc.ca</span></code>. So <code class="code docutils literal notranslate"><span class="pre">subdomain.testing.kub-eo.agr.gc.ca</span></code> will point to <code class="code docutils literal notranslate"><span class="pre">ingress.kub-eo.agr.gc.ca</span></code>. When a request to <code class="code docutils literal notranslate"><span class="pre">subdomain.testing.kub-eo.agr.gc.ca</span></code> is received, the load balancer can see which domain the request was for, and will forward it to the correct pod based on that instead of the port like NodePort services. This is the primary way that web services are built because using domains and subdomains instead of port numbers is much more user friendly.</p>
<p>The caveat to using ingress services is that a load balancer must be available. Cloud based providers have their own load balancers for you to use. If you are running your own bare metal cluster, you must use something like <a class="reference external" href="https://metallb.universe.tf/">metal lb</a> which provides a load balancer implementation for you to use.</p>
<div class="section" id="example-ingress-yaml">
<h3><a class="toc-backref" href="#id12">Example Ingress YAML</a><a class="headerlink" href="#example-ingress-yaml" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">networking.k8s.io/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Ingress</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-ingress</span>
<span class="nt">annotations</span><span class="p">:</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-body-size</span><span class="p">:</span> <span class="s">&quot;4000m&quot;</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-send-timeout</span><span class="p">:</span> <span class="s">&quot;600&quot;</span>
    <span class="nt">nginx.ingress.kubernetes.io/proxy-read-timeout</span><span class="p">:</span> <span class="s">&quot;600&quot;</span>
    <span class="nt">kubernetes.io/ingress.class</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">rules</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="nt">host</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">s2d2.kub-eo.agr.gc.ca</span>
    <span class="l l-Scalar l-Scalar-Plain">http</span><span class="p p-Indicator">:</span>
    <span class="nt">paths</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">backend</span><span class="p">:</span>
        <span class="nt">serviceName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api</span>
        <span class="nt">servicePort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8080</span>
</pre></div>
</div>
</div>
<div class="section" id="ingress-definition-key-aspects">
<h3><a class="toc-backref" href="#id13">Ingress Definition Key Aspects</a><a class="headerlink" href="#ingress-definition-key-aspects" title="Permalink to this headline">Â¶</a></h3>
<dl class="simple">
<dt><code class="code docutils literal notranslate"><span class="pre">annotations</span></code></dt><dd><p>Most load balancers use nginx as a reverse proxy, therefore there are some nginx settings that we can change for our ingress. If our ingress is sending big files back and forth, we can up the <code class="code docutils literal notranslate"><span class="pre">proxy-body-size</span></code> to 4 GB, and increase the timeouts to 5 minutes if transfers take a long time.</p>
</dd>
<dt><code class="code docutils literal notranslate"><span class="pre">rules</span></code></dt><dd><p>Here we set the domain that the ingress relates to, where the request should be sent to. In this case we are using a ClusterIP service that is listening on port 8080.</p>
</dd>
</dl>
</div>
<div class="section" id="ingress-commands">
<h3><a class="toc-backref" href="#id14">Ingress Commands</a><a class="headerlink" href="#ingress-commands" title="Permalink to this headline">Â¶</a></h3>
<p>You use similar commands to pods and services with ingresses, only with the <code class="code docutils literal notranslate"><span class="pre">ingress</span></code> resource type:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get ingress
</pre></div>
</div>
</div>
</div>
<div class="section" id="deployments">
<h2><a class="toc-backref" href="#id15">Deployments</a><a class="headerlink" href="#deployments" title="Permalink to this headline">Â¶</a></h2>
<p>Deployments are a way of bundling together manifests for pods, services, persistent volume claims, and more, into a single <code class="code docutils literal notranslate"><span class="pre">yaml</span></code> manifest. In addition, the deployment will automatically restart deleted pods, which makes it ideal for applications where the configuration changes a lot. Deployments get auto-generated names, so you will see deployments with names like <code class="code docutils literal notranslate"><span class="pre">deployment-name-adsfas-asdfas</span></code> with the last 2 suffixes being auto generated IDs for the deployment resource. In most cases, deployments with pods and services should be used instead of pod and service yamls individually.</p>
<p>In the <a class="reference internal" href="#helm-standardized-deployment-format"><span class="std std-ref">Helm and Helm Chart section</span></a> we go over the use of Helm to manage deployments, but it brings even more power such as variable templating, subcharts, and release versioning and rollbacks. Think of Helm and helm charts as deployments on steroids. You donât always need Helm, but you almost always should be using a deployment.</p>
<div class="section" id="example-deployment-yaml">
<h3><a class="toc-backref" href="#id16">Example Deployment YAML</a><a class="headerlink" href="#example-deployment-yaml" title="Permalink to this headline">Â¶</a></h3>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">apps/v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Deployment</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">selector</span><span class="p">:</span>
    <span class="nt">matchLabels</span><span class="p">:</span>
    <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api</span>
<span class="nt">replicas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">template</span><span class="p">:</span>
    <span class="nt">metadata</span><span class="p">:</span>
    <span class="nt">labels</span><span class="p">:</span>
        <span class="nt">app</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api</span>
    <span class="nt">spec</span><span class="p">:</span>
    <span class="nt">containers</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api</span>
        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry.cullen.io/jobmanager-api:v0.0.24</span>
        <span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;gunicorn&quot;</span><span class="p p-Indicator">]</span>
        <span class="nt">args</span><span class="p">:</span>
            <span class="p p-Indicator">[</span>
            <span class="s">&quot;--bind&quot;</span><span class="p p-Indicator">,</span>
            <span class="s">&quot;0.0.0.0:5000&quot;</span><span class="p p-Indicator">,</span>
            <span class="s">&quot;--log-level=debug&quot;</span><span class="p p-Indicator">,</span>
            <span class="s">&quot;jobmanager.wsgi&quot;</span><span class="p p-Indicator">,</span>
            <span class="s">&quot;--timeout&quot;</span><span class="p p-Indicator">,</span>
            <span class="s">&quot;300&quot;</span><span class="p p-Indicator">,</span>
            <span class="p p-Indicator">]</span>
        <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">5000</span>
            <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
        <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Always</span>
        <span class="nt">volumeMounts</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-vol</span>
            <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/media</span>
            <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/config.yaml</span>
            <span class="nt">subPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config-volume</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx</span>
        <span class="nt">image</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">registry.cullen.io/jobmanager-api:v0.0.24</span>
        <span class="nt">command</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;nginx&quot;</span><span class="p p-Indicator">]</span>
        <span class="nt">args</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="s">&quot;-g&quot;</span><span class="p p-Indicator">,</span> <span class="s">&quot;daemon</span><span class="nv"> </span><span class="s">off;&quot;</span><span class="p p-Indicator">]</span>
        <span class="nt">ports</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">80</span>
            <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
            <span class="p p-Indicator">-</span> <span class="nt">containerPort</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">443</span>
            <span class="nt">protocol</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">TCP</span>
        <span class="nt">imagePullPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Always</span>
        <span class="nt">volumeMounts</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-vol</span>
            <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/media</span>
            <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/config.yaml</span>
            <span class="nt">subPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config-volume</span>
            <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/nginx/sites-available/jobmanager</span>
            <span class="nt">subPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-siteconf</span>
            <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/etc/nginx/nginx.conf</span>
            <span class="nt">subPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx.conf</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-conf</span>
    <span class="nt">imagePullSecrets</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">regcred</span>
    <span class="nt">volumes</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-vol</span>
        <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
            <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-data</span>
        <span class="p p-Indicator">-</span> <span class="nt">configMap</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config</span>
            <span class="nt">items</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span>
                <span class="l l-Scalar l-Scalar-Plain">path</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config-volume</span>
        <span class="p p-Indicator">-</span> <span class="nt">configMap</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-siteconf</span>
            <span class="nt">items</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager</span>
                <span class="l l-Scalar l-Scalar-Plain">path</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-siteconf</span>
        <span class="p p-Indicator">-</span> <span class="nt">configMap</span><span class="p">:</span>
            <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-conf</span>
            <span class="nt">items</span><span class="p">:</span>
            <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx.conf</span>
                <span class="l l-Scalar l-Scalar-Plain">path</span><span class="p p-Indicator">:</span> <span class="l l-Scalar l-Scalar-Plain">nginx.conf</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-api-nginx-conf</span>
</pre></div>
</div>
<p>It may seem like there is a lot going on, but keep in mind that there is a lot of overlap with the previously covered resources we have seen before, pods and services.</p>
<p>Manifests can be bundled together in one file, seperated by <code class="code docutils literal notranslate"><span class="pre">---</span></code>. In this way we can include a service that the deployment will use at the top of the deployment manifest.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Service</span>
<span class="n">metadata</span><span class="p">:</span>
<span class="n">name</span><span class="p">:</span> <span class="n">jobmanager</span><span class="o">-</span><span class="n">api</span>
<span class="n">spec</span><span class="p">:</span>
<span class="n">ports</span><span class="p">:</span>
<span class="o">-</span> <span class="n">port</span><span class="p">:</span> <span class="mi">5000</span>
    <span class="n">protocol</span><span class="p">:</span> <span class="n">TCP</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">gunicorn</span>
<span class="o">-</span> <span class="n">port</span><span class="p">:</span> <span class="mi">8080</span>
    <span class="n">protocol</span><span class="p">:</span> <span class="n">TCP</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">static</span>
<span class="n">selector</span><span class="p">:</span>
    <span class="n">app</span><span class="p">:</span> <span class="n">jobmanager</span><span class="o">-</span><span class="n">api</span>
<span class="o">---</span>
<span class="n">apiVersion</span><span class="p">:</span> <span class="n">apps</span><span class="o">/</span><span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">Deployment</span>
<span class="n">metadata</span><span class="p">:</span>
<span class="n">name</span><span class="p">:</span> <span class="n">jobmanager</span><span class="o">-</span><span class="n">api</span>
<span class="n">spec</span><span class="p">:</span>
<span class="n">selector</span><span class="p">:</span>
    <span class="n">matchLabels</span><span class="p">:</span>
    <span class="n">app</span><span class="p">:</span> <span class="n">jobmanager</span><span class="o">-</span><span class="n">api</span>
<span class="n">replicas</span><span class="p">:</span> <span class="mi">1</span>
<span class="n">template</span><span class="p">:</span>
    <span class="n">metadata</span><span class="p">:</span>
    <span class="n">labels</span><span class="p">:</span>
        <span class="n">app</span><span class="p">:</span> <span class="n">jobmanager</span><span class="o">-</span><span class="n">api</span>
<span class="o">...</span>
</pre></div>
</div>
</div>
<div class="section" id="deployment-commands">
<h3><a class="toc-backref" href="#id17">Deployment Commands</a><a class="headerlink" href="#deployment-commands" title="Permalink to this headline">Â¶</a></h3>
<p>You use similar commands to pods and services with deployments, only with the <code class="code docutils literal notranslate"><span class="pre">deployment</span></code> resource type:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get deployment
</pre></div>
</div>
</div>
</div>
<div class="section" id="configmaps">
<h2><a class="toc-backref" href="#id18">Configmaps</a><a class="headerlink" href="#configmaps" title="Permalink to this headline">Â¶</a></h2>
<p>Configmaps are the resource to get configuration into your pods and deployments. Any configuration files or environment variables can be set with configmaps. You can set environment variables in a pod definition, but the recommended way to get credentials and config files into your pods is to use configmaps, as it will let you save whole files of config as yaml or json and have that yaml or json be mounted inside your container in a similar way to how data volume mounts work. That is why configmaps are accessed and added to to a pod in the same way that volume mounts from persistent volume claims are.</p>
<p>In the above <a class="reference internal" href="#example-deployment-yaml"><span class="std std-ref">example deployment YAML</span></a> there are configmaps being loaded and mounted as files inside the pods under the <code class="code docutils literal notranslate"><span class="pre">volumes</span></code> section. In this section we will go over how to create configmaps from config files, and more importantly how to update the configmap from a changed config file as your configurations change.</p>
<p>Regular volume mounts using a persistent volume claim name and a config map created using a <code class="code docutils literal notranslate"><span class="pre">.yaml</span></code> config file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">template</span><span class="p">:</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="l l-Scalar l-Scalar-Plain">container</span><span class="p p-Indicator">:</span>
    <span class="l l-Scalar l-Scalar-Plain">...</span>
    <span class="nt">volumeMounts</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-vol</span>
        <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/media</span>
        <span class="p p-Indicator">-</span> <span class="nt">mountPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/code/config.yaml</span> <span class="c1"># Path to mount the configmap</span>
        <span class="nt">subPath</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span> <span class="c1"># Specified so the configmap file mount doesn&#39;t replace the whole volume</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config-volume</span>
<span class="nt">volumes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-vol</span>
    <span class="nt">persistentVolumeClaim</span><span class="p">:</span>
        <span class="nt">claimName</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-media-data</span>
    <span class="p p-Indicator">-</span> <span class="nt">configMap</span><span class="p">:</span>
        <span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager-config</span>
        <span class="nt">items</span><span class="p">:</span>
        <span class="p p-Indicator">-</span> <span class="nt">key</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span> <span class="c1"># &lt;-- key that points to the YAML file</span>
            <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">config.yaml</span> <span class="c1"># &lt;-- name of the YAML file when it is created in the pod</span>
</pre></div>
</div>
<div class="section" id="example-creating-a-configmap">
<h3><a class="toc-backref" href="#id19">Example Creating A Configmap</a><a class="headerlink" href="#example-creating-a-configmap" title="Permalink to this headline">Â¶</a></h3>
<p>Assume you have a configuration file named <code class="code docutils literal notranslate"><span class="pre">config.yaml</span></code> that looks like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">S3_URL</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">http://s3.kub-eo.agr.gc.ca</span>
<span class="nt">S3_ACCESS_KEY</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;s3 access key here&gt;</span>
<span class="nt">S3_SECRET_KEY</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;s3 secret key here&gt;</span>
<span class="nt">S3_REGION</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">us-east-1</span>
<span class="nt">PSQL_DB</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanagerapp</span>
<span class="nt">PSQL_DB_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanagerapp</span>
<span class="nt">PSQL_DB_PASS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;db password here&gt;</span>
<span class="nt">PSQL_DB_URL</span><span class="p">:</span> <span class="s">&quot;10.96.107.240&quot;</span>
<span class="nt">PSQL_DB_PORT</span><span class="p">:</span> <span class="s">&quot;5432&quot;</span>
<span class="nt">USGS_EE_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;username here&gt;</span>
<span class="nt">USGS_EE_PASS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;password here&gt;</span>
<span class="nt">ESA_SCIHUB_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;username here&gt;</span>
<span class="nt">ESA_SCIHUB_PASS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;password here&gt;</span>
<span class="nt">DJANGO_SETTINGS_MODULE</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">jobmanager.settings</span>
<span class="nt">RABBIT_MQ_USER</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">user</span>
<span class="nt">RABBIT_MQ_PASS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;rabbit password here&gt;</span>
<span class="nt">RABBIT_MQ_URL</span><span class="p">:</span> <span class="s">&quot;10.96.181.64&quot;</span>
<span class="nt">RABBIT_MQ_PORT</span><span class="p">:</span> <span class="s">&quot;5672&quot;</span>
<span class="nt">DJANGO_SECRET</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;django secret here&gt;</span>
<span class="nt">REDIS_PASS</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;redis password here&gt;</span>
<span class="nt">REDIS_PORT</span><span class="p">:</span> <span class="s">&quot;6379&quot;</span>
<span class="nt">REDIS_HOST</span><span class="p">:</span> <span class="s">&quot;10.96.12.117&quot;</span>
<span class="nt">MAILGUN_API_URL</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">https://api.mailgun.net/v3/mg.satdat.space/messages</span>
<span class="nt">MAILGUN_API_KEY</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">&lt;api key here&gt;</span>
</pre></div>
</div>
<p>To create a config map from this file, you would use this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create configmap jobmanager-config --from-file config.yaml
</pre></div>
</div>
<p>If you have several versions of your config, but inside the pod the config needs a standardized name, you can rename the config for access inside the pod.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create configmap jobmanager-config --from-file<span class="o">=</span>config.yaml<span class="o">=</span> config_with_nonstandardname.yaml
</pre></div>
</div>
<p>So the config_with_nonstandardname.yaml will be renamed to config.yaml inside the pod. In this way, all of your config files do not have to be named the same.</p>
<p>To view your configmaps:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get configmaps

kubectl get configmap jobmanager-config -o yaml
</pre></div>
</div>
<p>The above command will let you see the structure of the files and values that make up your configmap. In the above case, the key <code class="code docutils literal notranslate"><span class="pre">config.yaml</span></code> will be assigned to a valid YAML serialized string, so that when the configmap is mounted, that key will be used to recreate the file and make it accessible inside the pod. Other keys and values can be stored inside a configmap.</p>
<p>To update your configmap:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl create configmap jobmanager-config --from-file config.yaml -o yaml --dry-run <span class="p">|</span> kubectl replace -f -
</pre></div>
</div>
<p>After you update your configmap, its a good idea to restart your pods with <code class="code docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">delete</span> <span class="pre">pod</span> <span class="pre">&lt;pod_name&gt;</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you are not using a deployment, your pod will not be recreated automatically, so donât forget to recreate the pod with <code class="code docutils literal notranslate"><span class="pre">kubectl</span> <span class="pre">apply</span> <span class="pre">-f</span> <span class="pre">pod_manifest.yaml</span></code></p>
</div>
<p>If you have user credentials that are common to many pods, it might be better to use a <a class="reference internal" href="#secrets"><span class="std std-ref">secret</span></a>, similar to how we use a secret for the docker private registry credentials in order to pull docker images. But keep in mind, secrets provide no security beyond configmaps by default. It is just another resource type for credentials that are common across your cluster. Donât assume secrets are secret.</p>
</div>
</div>
<div class="section" id="secrets">
<h2><a class="toc-backref" href="#id20">Secrets</a><a class="headerlink" href="#secrets" title="Permalink to this headline">Â¶</a></h2>
<p>Secrets are base64 encoded configuration and credential storage. Most useful for common config across many pods, or to standardize how you store credentials in your cluster.</p>
<p>An example of creating a secret is the docker private registry secret, where the docker login credentials stored in a .json file are saved in a secret and used by pods to pull the docker image they need.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>  kubectl create secret generic <span class="k">do</span>-registry <span class="se">\</span>
--from-file<span class="o">=</span>.dockerconfigjson<span class="o">=</span>docker-config.json <span class="se">\</span>
--type<span class="o">=</span>kubernetes.io/dockerconfigjson
</pre></div>
</div>
<p>Secrets are very similar to configmaps, except they are base64 encoded. So to get a secret you would retrieve the secret as a yaml:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>kubectl get secret secret-name -o yaml

apiVersion: v1
data:
redis-password: <span class="nv">Q2p3QlR6cmg5Wg</span><span class="o">==</span> <span class="c1"># base64 encoded credential we are looking for</span>
kind: Secret
metadata:
...
</pre></div>
</div>
<p>To view the credential, we need to decode it like so:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">echo</span> <span class="nv">Q2p3QlR6cmg5Wg</span><span class="o">==</span> <span class="p">|</span> base64 --decode

CjwBTzrh9Z
</pre></div>
</div>
</div>
<div class="section" id="persistent-volumes-and-claims">
<h2><a class="toc-backref" href="#id21">Persistent Volumes and Claims</a><a class="headerlink" href="#persistent-volumes-and-claims" title="Permalink to this headline">Â¶</a></h2>
<p>Persistent volumes allow you to you store data across pod restarts, and share data among pods in the case of NFS shares. Persistent volumes are the general storage resource, and persistent volume claims are specific claims to chunks of those persistent volumes which are dedicated to specific pods.</p>
<p>In addition to manually specified persistent volumes and persistent volume claims, there are storage classes which enable auto provisioning. This means that when a pod requests a certain amount of storage from a storage class that supports provisioning, the provisioner automatically creates the claim and allows the pod to access it. You donât have to create the PV and PVC, they are created for you by the provisioner when you create the pod.</p>
<div class="section" id="example-persistent-volume-and-claim-yaml">
<h3><a class="toc-backref" href="#id22">Example Persistent Volume and Claim YAML</a><a class="headerlink" href="#example-persistent-volume-and-claim-yaml" title="Permalink to this headline">Â¶</a></h3>
<p>Persistent volume:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolume</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-pv-miniostorage</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">capacity</span><span class="p">:</span>
    <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10Ti</span>
<span class="nt">accessModes</span><span class="p">:</span>
    <span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
<span class="nt">persistentVolumeReclaimPolicy</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">Retain</span>
<span class="nt">nfs</span><span class="p">:</span>
    <span class="nt">path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">/mnt/md0/minio_storage</span>
    <span class="nt">server</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10.117.206.94</span>
    <span class="nt">readOnly</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
</pre></div>
</div>
<p>Persistent volume claim:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">apiVersion</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">v1</span>
<span class="nt">kind</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">PersistentVolumeClaim</span>
<span class="nt">metadata</span><span class="p">:</span>
<span class="nt">name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">nfs-pvc-miniostorage</span>
<span class="nt">spec</span><span class="p">:</span>
<span class="nt">accessModes</span><span class="p">:</span>
<span class="p p-Indicator">-</span> <span class="l l-Scalar l-Scalar-Plain">ReadWriteMany</span>
<span class="nt">resources</span><span class="p">:</span>
    <span class="nt">requests</span><span class="p">:</span>
    <span class="nt">storage</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10Ti</span>
</pre></div>
</div>
<p>The persistent volume references a specific type of storage, whether that is block storage provided by a cloud provider, an nfs share specified by export and IP address of the server, or others. It is the actual storage that persistence volume claims can try to access and provide to the pods that have references to those claims.</p>
<p>The persistent volume claim sets the requirements, and then Kubernetes tries to find a matching persistent volume that can meet those requirements. Usually if you only have one persistent volume and claim being created at a time, the correct persistent volume will be matched to your persistent volume claim, if it is able to meet the requirements of the persistent volume claim. If you want to explicitly match PV and PVC, you can use a <code class="code docutils literal notranslate"><span class="pre">claimRef</span></code> in the PV and <code class="code docutils literal notranslate"><span class="pre">volumeName</span></code> in the PVC.</p>
</div>
<div class="section" id="nfs">
<h3><a class="toc-backref" href="#id23">NFS</a><a class="headerlink" href="#nfs" title="Permalink to this headline">Â¶</a></h3>
<p>NFS shares as persistent volumes allows ReadWriteMany data access, which allows multiple pods to read and write from the same volume at the same time. If we create an NFS server outside of the cluster, we can access the data in the persistent volume as a normal network share. The trade off is that auto provisioning is not possible.</p>
<p>NFS shares can be mounted ephemerally directly in the pod manifest, or through persistent volumes and claims, which are then referenced in the pod manifest. The primary difference is you should use persistent volumes if you want the NFS share to managed by Kubernetes and documented in your source control. This should be used if the shares are used across many different pods, as you would only have to change persistent volume or claim once, instead of all of the pods where the NFS settings are defined.</p>
<p>See this <a class="reference external" href="https://cloud.netapp.com/blog/kubernetes-nfs-two-quick-tutorials-cvo-blg">article</a> for more info on NFS and the different ways to access the network shares in your pods.</p>
</div>
<div class="section" id="auto-provisioning">
<h3><a class="toc-backref" href="#id24">Auto Provisioning</a><a class="headerlink" href="#auto-provisioning" title="Permalink to this headline">Â¶</a></h3>
<p>Auto provisioning is when a persistent volume claim is specified with a storage class that with a supporting provisioner. When the claim is specified, the corresponding volume is created automatically. There is an <a class="reference external" href="https://github.com/helm/charts/tree/master/stable/nfs-server-provisioner">NFS provisioner helm chart</a>, which will create NFS persistence volumes automatically. The trade off is that these NFS volumes are not accessible outside the cluster, and mounting them as regular network shares is not possible (or at least not easy).</p>
<p>On bare metal clusters, where block device volume storage from cloud providers is not available, dynamic provisioning is possible through the use of <a class="reference external" href="https://openebs.io/">OpenEBS</a>. A <a class="reference external" href="https://docs.openebs.io/docs/next/cstor.html">cstor storage pool</a> of block devices can be created using block devices on each node, which creates a pool of storage that you can use to create persistent volumes from. After you create the pool and name the storage class, you can use that storage class in helm charts and deployments to create the persistent volume from the storage pool automatically.</p>
</div>
</div>
<div class="section" id="helm-standardized-deployment-format">
<h2><a class="toc-backref" href="#id25">Helm: Standardized Deployment Format</a><a class="headerlink" href="#helm-standardized-deployment-format" title="Permalink to this headline">Â¶</a></h2>
<p>Helm is a tool that allows you to deploy a set of resources to Kubernetes in a standardized and customizable way. You can bundle complex configurations, dependencies in a format called a helm chart that can be transferred and customized through templating that allows users to install your application with minimal effort. In addition, helm will track the version of the application, allowing for easy rollbacks if things go wrong. Helm charts can be simple or very complex, but in any case it is a good idea to become comforatable with Helm and Helm charts, as you will often be using them to install 3rd party dependencies for your application, such as Postgres, RabbitMQ, Redis, Minio, and others.</p>
<p>Follow the directions in the <a class="reference external" href="https://helm.sh/docs/intro/quickstart/">official Helm docs</a> to install Helm and begin using it.</p>
<div class="section" id="example-of-using-helm">
<h3><a class="toc-backref" href="#id26">Example of Using Helm</a><a class="headerlink" href="#example-of-using-helm" title="Permalink to this headline">Â¶</a></h3>
<p>Here we are going to use Helm to install Postgres on our cluster.</p>
<p>First we find the postgres helm chart we want to use. In this case we will be using the <a class="reference external" href="https://github.com/bitnami/charts/tree/master/bitnami/postgresql">bitnami helm chart</a>.</p>
<p>Then we make sure we have the bitnami repo added to helm:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm repo add bitnami https://charts.bitnami.com/bitnami

helm repo update
</pre></div>
</div>
<p>Then we install postgres, setting the release name to <code class="code docutils literal notranslate"><span class="pre">psql</span></code>, using all the default settings:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install psql bitnami/postgresql
</pre></div>
</div>
<p>More likely, we would want to change a few settings, so we would use the <code class="code docutils literal notranslate"><span class="pre">--set</span></code> arg to change some configuration settings:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm install psql bitnami/postgresql --set persistence.storageClass<span class="o">=</span>openebs-hdd-storageclass,persistence.size<span class="o">=</span>100Gi,postgresqlPassword<span class="o">=</span>sBwqls0FpQ
</pre></div>
</div>
<p>You can view all the available configuration options on the <a class="reference external" href="https://github.com/bitnami/charts/tree/master/bitnami/postgresql#parameters">chart repo ReadMe</a>.</p>
<p>To see the current helm installs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm list
</pre></div>
</div>
<p>To remove a helm install:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>helm uninstall psql
</pre></div>
</div>
</div>
<div class="section" id="helm-charts">
<h3><a class="toc-backref" href="#id27">Helm Charts</a><a class="headerlink" href="#helm-charts" title="Permalink to this headline">Â¶</a></h3>
<p>If you have a complex application, you can make it easier to install for you and others by creating a helm chart to bundle it together.</p>
<p>The general format of a helm chart has this structure:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">root</span><span class="o">/</span>
    <span class="o">.</span><span class="n">helmignore</span>
    <span class="n">Chart</span><span class="o">.</span><span class="n">yaml</span>
    <span class="n">values</span><span class="o">.</span><span class="n">yaml</span>
    <span class="n">templates</span><span class="o">/</span>
    <span class="n">charts</span><span class="o">/</span>
    <span class="n">configfiles</span><span class="o">/</span>
</pre></div>
</div>
<p>The <code class="code docutils literal notranslate"><span class="pre">templates</span></code> directory contains your yaml manifests for the different resources for your application. Inside the yaml files you can add templating directives that pulls values from the <code class="code docutils literal notranslate"><span class="pre">values.yaml</span></code> file.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">apiVersion</span><span class="p">:</span> <span class="n">v1</span>
<span class="n">kind</span><span class="p">:</span> <span class="n">PersistentVolume</span>
<span class="n">metadata</span><span class="p">:</span>
<span class="n">name</span><span class="p">:</span> <span class="n">nfs</span><span class="o">-</span><span class="n">pv</span><span class="o">-</span><span class="p">{{</span> <span class="n">include</span> <span class="s2">&quot;jobmanager-api.fullname&quot;</span> <span class="o">.</span> <span class="p">}}</span> <span class="c1"># templating directive</span>
<span class="n">spec</span><span class="p">:</span>
<span class="n">capacity</span><span class="p">:</span>
    <span class="n">storage</span><span class="p">:</span> <span class="mi">14</span><span class="n">Ti</span>
<span class="n">accessModes</span><span class="p">:</span>
    <span class="o">-</span> <span class="n">ReadWriteMany</span>
<span class="n">persistentVolumeReclaimPolicy</span><span class="p">:</span> <span class="n">Retain</span>
<span class="n">nfs</span><span class="p">:</span>
    <span class="n">path</span><span class="p">:</span> <span class="o">/</span><span class="n">mnt</span><span class="o">/</span><span class="n">drobo</span>
    <span class="n">server</span><span class="p">:</span> <span class="n">zeus684440</span><span class="o">.</span><span class="n">agr</span><span class="o">.</span><span class="n">gc</span><span class="o">.</span><span class="n">ca</span>
    <span class="n">readOnly</span><span class="p">:</span> <span class="n">false</span>
</pre></div>
</div>
<p>The  <code class="code docutils literal notranslate"><span class="pre">values.yaml</span></code> file is where you setup your default values for your helm chart, and these are also the values that can be overridden by the user with the <code class="code docutils literal notranslate"><span class="pre">--set</span></code> args when installing the helm chart.</p>
<p><code class="code docutils literal notranslate"><span class="pre">Chart.yaml</span></code> contains general info about your chart, such as version, dependencies, and other packaging info.</p>
<p>The <code class="code docutils literal notranslate"><span class="pre">charts/</span></code> directory is where you would put subcharts that your chart depends on. Subcharts are full helm charts that your main chart requires to function. So here you could add subcharts for postgres and rabbitmq if your application required those applications to function. Subcharts, and full charts, can be stored as compressed tar archives.</p>
<p>A helm ârepoâ is a simple web accessible directory with helm charts stored as compressed tar archives with the correct naming convention (<code class="code docutils literal notranslate"><span class="pre">postgresql-8.2.1.tgz</span></code>) and an <code class="code docutils literal notranslate"><span class="pre">index.yaml</span></code> file that summarizes the available helm charts in the repo.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="example1-agricartapreprocessing.html" class="btn btn-neutral float-right" title="Example 1 - Simple - Agricarta Preprocessing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="docker.html" class="btn btn-neutral float-left" title="Docker" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Shaun Cullen

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>